{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lean version of read in file for the NMX work flow (from simulatet event data to binned event data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "first add neded libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "startTime = datetime.now()\n",
    "import tracemalloc\n",
    "    #from scippnexus import data\n",
    "#import scippnexus as snx\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "    #qimport mantid_args\n",
    "#from scippnexus import NXdetector\n",
    "from scippneutron.conversion import graph\n",
    "\n",
    "import scipp as sc\n",
    "import scippneutron as scn\n",
    "import scippnexus as snx\n",
    "\n",
    "#%matplotlib widget\n",
    "\n",
    "\n",
    "import plopp as pp\n",
    "pp.patch_scipp()\n",
    "import matplotlib.pyplot as plt\n",
    "from plopp.widgets import Box\n",
    "import ipywidgets as ipw\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "    #import multiprocessing as mp\n",
    "\n",
    "import h5py\n",
    "h5py.enable_ipython_completer()\n",
    "%matplotlib inline\n",
    "%matplotlib widget\n",
    "\n",
    "# starting the momory monitoring\n",
    "tracemalloc.start()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define general parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number op pixels per detecotr dimmension\n",
    "pix = 1280\n",
    "#number of time bins \n",
    "t_step = 250\n",
    "#number of detectors\n",
    "n_det = 3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pretreatment to make it faster\n",
    "h5repack -l CHUNK=1024x6 2e11.h5 2e11-rechunk.h5 \n",
    "or \n",
    "h5repack -l CHUNK=NONE 2e11.h5 2e11-nochunk.h5\n",
    "\n",
    "h5repack -l CHUNK=1024x6 mccode.h5 mccode-nochunk.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 14\n",
    "\n",
    "if fname == 1:\n",
    "   filename = '/Users/justinbergmann/work_flow/test_data/2e11.h5'\n",
    "elif fname == 2:\n",
    "    filename = '/Users/justinbergmann/work_flow/test_data/x0_3d.h5'\n",
    "elif fname == 3:\n",
    "    filename = '/Users/justinbergmann/work_flow/test_data/xe_0_NMX.h5'\n",
    "elif fname == 4:\n",
    "    filename = '/Users/justinbergmann/work_flow/test_data/xe_20_NMX.h5'\n",
    "elif fname == 5:\n",
    "    filename = '/Users/justinbergmann/work_flow/test_data/flip_det.h5'\n",
    "elif fname == 6:\n",
    "    filename = '/Users/justinbergmann/work_flow/test_data/flip_4.h5'\n",
    "elif fname == 7:\n",
    "    filename = '/Users/justinbergmann/work_flow/test_data/ye_0_NMX.h5'\n",
    "elif fname == 8:\n",
    "    filename = '/Users/justinbergmann/work_flow/test_data/xe1_12_NMX/xe1_12_no_chunk.h5'\n",
    "elif fname == 9:\n",
    "    filename = '/Users/justinbergmann/work_flow/test_data/1d.h5'\n",
    "\n",
    "elif fname == 10:\n",
    "    filename = '/Users/justinbergmann/work_flow/test_data/xflat20.h5'\n",
    "\n",
    "elif fname == 11:\n",
    "    filename = '/Users/justinbergmann/work_flow/test_data/small_vis/flat.nxs'\n",
    "\n",
    "elif fname == 12:\n",
    "    filename = '/Users/justinbergmann/work_flow/test_data/small_vis/shift_down.nxs'\n",
    "\n",
    "\n",
    "elif fname == 13:\n",
    "    filename = '/Users/justinbergmann/work_flow/test_data/mc2_7_2_test.h5'\n",
    "\n",
    "elif fname == 14:\n",
    "    filename = '/Users/justinbergmann/work_flow/test_data/mc2_new_comp.nxs'\n",
    "\n",
    "\n",
    "\n",
    "else:\n",
    "    filename = '/Users/justinbergmann/work_flow/test_data/e12_no_chunk.h5'\n",
    "\n",
    "\n",
    "f_vis = '/Users/justinbergmann/work_flow/test_data/ye_0_NMX_vis.nxs'\n",
    "# f_vis ='/Users/justinbergmann/work_flow/test_data/mc2_new_comp_vis.nxs' \n",
    "\n",
    "#f=snx.File(filename)    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read in event data and shape event list  give number of events"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3D visulisation with file converted by mantid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = sc.io.open_hdf5(filename = f_vis)\n",
    "scn.instrument_view(vis.sum('tof'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "f = h5py.File(filename)\n",
    "a = f['entry1/data']['bank01_events_dat_list_p_x_y_n_id_t']['events'][...]\n",
    "#a[0]\n",
    "d = np.matrix.transpose(a)\n",
    "print(\"shape of event list (p_x_y_n_id_t)\", d.shape)\n",
    "#alocate units to events and create seperate list for each parameter\n",
    "x_list = sc.array(dims=['x'], unit='m', values=d[1])\n",
    "y_list = sc.array(dims=['x'], unit='m', values=d[2])\n",
    "t_list = sc.array(dims=['x'], unit='s', values=d[5])\n",
    "id_list = sc.array(dims=['x'], unit=None, values=d[4], dtype='int64')\n",
    "#print(x_list.shape, y_list.shape, t_list.shape,id_list.shape)\n",
    "\n",
    "#get evetns to seperated lists (x,y,t,id)\n",
    "#x_list.unit = 'm'\n",
    "#y_list.unit = 'm'\n",
    "#t_list.unit = 'ms'\n",
    "weights = sc.ones_like(x_list)\n",
    "weights.unit = 'counts'\n",
    "da = sc.DataArray(data=weights, coords={'x': x_list, 'y': y_list, 't': t_list, 'id': id_list})\n",
    "\n",
    "#make sure alll IDs are reconised:\n",
    "print(\"id min\",id_list.values.min())\n",
    "print(\"id max\",id_list.values.max())\n",
    "\n",
    "ids1 = sc.arange('id', 1, 1638401, unit=None)\n",
    "ids2 = sc.arange('id', 2000001, 3638401, unit=None)\n",
    "ids3 = sc.arange('id', 4000001, 5638401, unit=None)\n",
    "ids = sc.concat([ids1, ids2, ids3], 'id')\n",
    "#grouping by IDs\n",
    "da3 = da.group(ids).fold('id', sizes={'panel':3, 'id':-1})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "treatment and plotting of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binning of each detector panel in t_step bins\n",
    "panel_0 = da3['panel',0].hist(t=t_step)\n",
    "panel_1 = da3['panel',1].hist(t=t_step)\n",
    "panel_2 = da3['panel',2].hist(t=t_step)\n",
    "\n",
    "p0 = pp.slicer(da3.fold('id', sizes={'ypix':pix, 'xpix':-1})['panel', 0].hist(t=t_step).transpose(['t','ypix','xpix']),vmax=panel_0.max().value, aspect='equal',title='panel 0')\n",
    "p1 = pp.slicer(da3.fold('id', sizes={'ypix':pix, 'xpix':-1})['panel', 1].hist(t=t_step).transpose(['t','ypix','xpix']),vmax=panel_1.max().value, aspect='equal',title='panel 1')\n",
    "p2 = pp.slicer(da3.fold('id', sizes={'ypix':pix, 'xpix':-1})['panel', 2].hist(t=t_step).transpose(['t','ypix','xpix']),vmax=panel_2.max().value, aspect='equal',title='panel 2')\n",
    "\n",
    "#p0.children[0].ax.set_ylim(1280, 0)\n",
    "#p1.children[0].ax.set_ylim(1280, 0)\n",
    "#p2.children[0].ax.set_ylim(1280, 0)\n",
    "\n",
    "p0.children[0].ax.set_xlim(0, 1280)\n",
    "p1.children[0].ax.set_xlim(0, 1280)\n",
    "\n",
    "p2.children[0].ax.set_xlim(0, 1280)\n",
    "\n",
    "l1 = ipw.jslink((p0.children[1].children[0].children[1], 'value'),\n",
    "               (p1.children[1].children[0].children[1], 'value'))\n",
    "l2 = ipw.jslink((p0.children[1].children[0].children[1], 'value'),\n",
    "               (p2.children[1].children[0].children[1], 'value'))\n",
    "Box([[p2, p0, p1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = da.group('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_t = grouped.hist(t=t_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"da\",da.shape)\n",
    "print(\"normal\", grouped.shape)\n",
    "print(\"bin\",group_t.shape)\n",
    "print(2000000-1280**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.bins.size().plot(ignore_size=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(group_t.coords['t'].shape)\n",
    "print(group_t.coords['id'].values.shape)\n",
    "print(group_t.values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f.filename)\n",
    "print(f.file)\n",
    "print(f.driver)\n",
    "print(f.mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.coords['panel'] = id_list // sc.index(2000000)\n",
    "da2 = da.group('panel').bin(x=pix, y=pix)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "up data reagarding ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(panel_0.values.shape)\n",
    "print( \"t_min\",t_list.min().value, \"t_max\",t_list.max().value)\n",
    "t_min =t_list.min().value \n",
    "t_max =t_list.max().value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "ts with slicer to scan TOF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which time of the pulse do we chose as T0 for TOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p1f = da3.fold('id', sizes={'xpix':1280, 'ypix':-1})['panel', 0].hist(t=t_step)\n",
    "#p11 = da3['panel',0] #.hist(t=t_step)\n",
    "#p11[0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dd 2D binning (x and y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p12 = p11.bins\n",
    "#sc.show(p1f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p1n = p1f.values\n",
    "#print(p1n.shape)\n",
    "#p1n[0][0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s1 = p1f['t',0]\n",
    "#s2 = s1.values\n",
    "#print(s2.shape,s2[0][0])\n",
    "\n",
    "#s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p11.values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getting all important things to wrire about the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c0 = panel_0.values\n",
    "c0.shape\n",
    "t0 = panel_0.coords['t'].values\n",
    "id0 = panel_0.coords['id'].values\n",
    "c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(filename)\n",
    "a = f['entry1/data']['bank01_events_dat_list_p_x_y_n_id_t']['events'][...]\n",
    "d = np.matrix.transpose(a)\n",
    "print(d.shape)\n",
    "\n",
    "\n",
    "x_list = sc.array(dims=['x'], unit='m', values=d[1])\n",
    "y_list = sc.array(dims=['x'], unit='m', values=d[2])\n",
    "t_list = sc.array(dims=['x'], unit='ms', values=d[5])\n",
    "id_list = sc.array(dims=['x'], unit='none', values=d[4])\n",
    "print(x_list.shape, y_list.shape, t_list.shape,id_list.shape)\n",
    "weights = sc.ones_like(x_list)\n",
    "weights.unit = 'counts'\n",
    "da = sc.DataArray(data=weights, coords={'x': x_list, 'y': y_list, 't': t_list, 'id': id_list})\n",
    "print(da)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "nbin= 1280\n",
    "binned = da.bin(y=nbin, x=nbin)\n",
    "#binned = da.bin(y=50, x=50)\n",
    "#binned = da.bin(y=225, x=225)\n",
    "#sc.transpose(binned)\n",
    "\n",
    "binned\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3D binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbin=300\n",
    "hist3=binned.hist(t=tbin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "histrogramm 3D data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "plot t slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nb=60\n",
    "#times=hist3.coords['t']\n",
    "#print(len(times))\n",
    "#print(len(times),times[nb],times[nb+1])\n",
    "#hist3['t',nb].transpose().plot(aspect='equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn with pixel id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del hist3.coords['tc']\n",
    "# del hist3.coords['xc']\n",
    "# del hist3.coords['yc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist4 = hist3.copy()\n",
    "for name in list(hist4.coords.keys()):\n",
    "    hist4.coords[f'{name}c'] = sc.midpoints(hist4.coords[name])\n",
    "hist4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "300*300*200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist5 = sc.flatten(hist4, to='row')\n",
    "ava = np.average(hist5.values) #avarage of values to use as cut off creteria\n",
    "sig = np.std(hist5.values)\n",
    "cut = ava + sig*10\n",
    "#print(\"background substraction\",cut, ava, sig)\n",
    "select = hist5.data > sc.scalar(cut, unit='counts') # cut of background\n",
    "filtered = hist5[select]\n",
    "filtered.coords['tc'] *= 10\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ava = np.average(hist5.values)\n",
    "sig = np.std(hist5.values)\n",
    "#print(ava, sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbin= pix\n",
    "nbin = 250\n",
    "binned = da.bin(y=nbin, x=nbin)\n",
    "#binned = da.bin(y=50, x=50)\n",
    "#binned = da.bin(y=225, x=225)\n",
    "#sc.transpose(binned)\n",
    "\n",
    "binned\n",
    "\n",
    "hist3=binned.hist(t=t_step)\n",
    "\n",
    "hist4 = hist3.copy()\n",
    "for name in list(hist4.coords.keys()):\n",
    "    hist4.coords[f'{name}c'] = sc.midpoints(hist4.coords[name])\n",
    "hist4\n",
    "\n",
    "hist5 = sc.flatten(hist4, to='row')\n",
    "ava = np.average(hist5.values) #avarage of values to use as cut off creteria\n",
    "sig = np.std(hist5.values)\n",
    "cut = ava + sig*2\n",
    "#print(\"background substraction\",cut, ava, sig)\n",
    "select = hist5.data > sc.scalar(cut, unit='counts') # cut of background\n",
    "filtered = hist5[select]\n",
    "filtered.coords['tc'] *= 10\n",
    "filtered\n",
    "\n",
    "pp.scatter3d(filtered, x='xc', y='yc', z='tc', pixel_size=0.001)#,figsize=(550, 550))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.scatter3d(filtered, x='xc', y='yc', z='tc', pixel_size=0.001)#,figsize=(550, 550))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbin= 1280**2\n",
    "print(nbin)\n",
    "tbin = 12\n",
    "id_binned = da.bin(id=nbin)\n",
    "\n",
    "id_hist=id_binned.hist(t=tbin)\n",
    "\n",
    "\n",
    "id_hist.sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f_out = h5py.File('/Users/justinbergmann/work_flow/test_out/test.h5','w')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "detector postion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origen = f['entry1/data']['bank01_events_dat_list_p_x_y_n_id_t']['distance'][0].decode()\n",
    "origen = list(np.float_(origen.split()))\n",
    "origen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origen_l = f['entry1/data']['bank01_events_dat_list_p_x_y_n_id_t']['distance'][...]\n",
    "print(origen_l)\n",
    "\n",
    "o_l = origen_l[0].split()\n",
    "print(\"#######\")\n",
    "print(\"123\",o_l)\n",
    "det_or = []\n",
    "for i in range(len(o_l)):\n",
    "    det_or.append(float(o_l[i]))\n",
    "#x = float(ol[0])\n",
    "det_or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = h5py.File(filename)\n",
    "#abc = f['entry1/instrument/instrument_xml'].keys() \n",
    "print( f['entry1/instrument/instrument_xml/data'])\n",
    "\n",
    "f['entry1/instrument/instrument_xml/data']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def CDist2(A,B):\n",
    "#calculate distance betweenn two points\n",
    "        dist = len3dvec(twoP_to_vec(A, B))\n",
    "        return dist\n",
    "\n",
    "\n",
    "\n",
    "def len3dvec(vec):\n",
    "## calculates lengh of a 3D vecor\n",
    "## input as list\n",
    "        a = np.sqrt(vec[0]**2 + vec[1]**2 + vec[2]**2)\n",
    "        return a\n",
    "\n",
    "def twoP_to_vec(A,B):\n",
    "#creates vector between two points\n",
    "        vec = np.array([B[0]-A[0], B[1]-A[1], B[2]-A[2]])\n",
    "\n",
    "        return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml  = str(f['entry1/instrument/instrument_xml/data'][...][0]).split('\\\\n')\n",
    "# xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_matrix(axis, theta):\n",
    "    \"\"\"\n",
    "    Return the rotation matrix associated with counterclockwise rotation about\n",
    "    the given axis by theta radians.\n",
    "    \"\"\"\n",
    "    axis = np.asarray(axis)\n",
    "    axis = axis / math.sqrt(np.dot(axis, axis))\n",
    "    a = math.cos(theta / 2.0)\n",
    "    b, c, d = -axis * math.sin(theta / 2.0)\n",
    "    aa, bb, cc, dd = a * a, b * b, c * c, d * d\n",
    "    bc, ad, ac, ab, bd, cd = b * c, a * d, a * c, a * b, b * d, c * d\n",
    "    return np.array([[aa + bb - cc - dd, 2 * (bc + ad), 2 * (bd - ac)],\n",
    "                     [2 * (bc - ad), aa + cc - bb - dd, 2 * (cd + ab)],\n",
    "                     [2 * (bd + ac), 2 * (cd - ab), aa + dd - bb - cc]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = False\n",
    "det = False\n",
    "source = False\n",
    "sample = False\n",
    "sample_pos = [0,0,0]\n",
    "source_pos = [0,0,0]\n",
    "d_list = []\n",
    "rot_l = []\n",
    "fast_l = []\n",
    "slow_l = []\n",
    "\n",
    "\n",
    "for i in range(len(xml)):\n",
    "    ls = xml[i].replace('<t',' ').replace('>',' ').replace('\"',' ').replace('<',' ').replace('\\\\t',' ').split()\n",
    "    \n",
    "    if len(ls) >= 1:\n",
    "        if ls[0] == 'component':\n",
    "            det = False\n",
    "            source = False\n",
    "            sample = False\n",
    "            comp = True\n",
    "            if ls[2].split('-')[0] == 'MonNDtype':\n",
    "\n",
    "                det = True\n",
    "                d_list.append([int(ls[2].split('-')[1])])\n",
    "            elif ls[2] == 'sourceMantid-type':\n",
    "                source = True\n",
    "            elif ls[2] == 'sampleMantid-type':\n",
    "                sample = True\n",
    "            comp = True\n",
    "     #   if ls[1].split('-')[0] == 'type=\"MonNDtype':\n",
    "            # print(\"1\",ls)\n",
    "    if len(ls) >= 1:\n",
    "        if ls[0] == 'type':\n",
    "            comp = False\n",
    "    if len(ls) >= 1:\n",
    "        if ls[0] == 'location' or ls[0] == 'location':\n",
    "            # print(\"3\",ls)\n",
    "            if comp == True and det == True:\n",
    "                print(\"2\",ls)\n",
    "                xyz = [float(ls[2]),float(ls[4]),float(ls[6])]\n",
    "                rot =float(ls[8]) \n",
    "                rot_xyz =[ float(ls[8]), float(ls[10]),float(ls[12]),float(ls[14])] \n",
    "                print(\"rotation of detector\",rot, rot_xyz) \n",
    "                d_list[len(d_list)-1].append(xyz)\n",
    "                rot_l.append(rot_xyz)\n",
    "            elif comp == True and source == True: \n",
    "              source_pos = [float(ls[2]),float(ls[4]),float(ls[6])]\n",
    "            elif comp == True and sample == True: \n",
    "               sample_pos = [float(ls[2]),float(ls[4]),float(ls[6])]\n",
    "print(len(d_list))\n",
    "print(\"sample and source position\",sample_pos,source_pos)\n",
    "print(\"distance between sample and source\",CDist2(source_pos, sample_pos))\n",
    "print(\"detector positions, relative to source at 0,0,0:\",d_list)\n",
    "print(\"rotation list\",rot_l)\n",
    "#shift from rleative position to source to relative to sample\n",
    "ds_l = []\n",
    "for i in range(len(d_list)):\n",
    "    rel_xyz = [ d_list[i][1][0]-sample_pos[0],d_list[i][1][1]-sample_pos[1],d_list[i][1][2]-sample_pos[2]]\n",
    "    ds_l.append(rel_xyz)\n",
    "vec_f = [0,0,1]\n",
    "vec_s = [0,1,0]\n",
    "for i in range(len(rot_l)):\n",
    "    theta = np.radians(rot_l[i][0])\n",
    "    v = [rot_l[i][1],rot_l[i][2],rot_l[i][3]]\n",
    "    fast_l.append(np.dot(rotation_matrix(v, theta), vec_f))\n",
    "    slow_l.append(np.dot(rotation_matrix(v, theta), vec_s))\n",
    "\n",
    "print(\"relative to sample position\",ds_l)\n",
    "print(\"fast axis\",fast_l)\n",
    "print(\"slow axis\", slow_l)\n",
    "print(rot_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_matrix(axis, theta):\n",
    "    \"\"\"\n",
    "    Return the rotation matrix associated with counterclockwise rotation about\n",
    "    the given axis by theta radians.\n",
    "    \"\"\"\n",
    "    axis = np.asarray(axis)\n",
    "    axis = axis / math.sqrt(np.dot(axis, axis))\n",
    "    a = math.cos(theta / 2.0)\n",
    "    b, c, d = -axis * math.sin(theta / 2.0)\n",
    "    aa, bb, cc, dd = a * a, b * b, c * c, d * d\n",
    "    bc, ad, ac, ab, bd, cd = b * c, a * d, a * c, a * b, b * d, c * d\n",
    "    return np.array([[aa + bb - cc - dd, 2 * (bc + ad), 2 * (bd - ac)],\n",
    "                     [2 * (bc - ad), aa + cc - bb - dd, 2 * (cd + ab)],\n",
    "                     [2 * (bd + ac), 2 * (cd - ab), aa + dd - bb - cc]])\n",
    "\n",
    "v = [0, 1, 0]\n",
    "axis = [0, -1, 0]\n",
    "rotation_degrees = 45\n",
    "\n",
    "theta  = np.radians(rotation_degrees)\n",
    "vec_out=np.dot(rotation_matrix(axis, theta), v)\n",
    "\n",
    "print(np.round(vec_out,10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getting the crystal orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((f['entry1']['simulation']['Param'].keys()))\n",
    "print((f['entry1']['simulation']['Param']['XtalPhiX']))\n",
    "phix=float(list(str(f['entry1']['simulation']['Param']['XtalPhiX'][...][0]))[2])\n",
    "phiy=float(list(str(f['entry1']['simulation']['Param']['XtalPhiY'][...][0]))[2])\n",
    "phiz=float(list(str(f['entry1']['simulation']['Param']['XtalPhiZ'][...][0]))[2])\n",
    "#str(phix[0])\n",
    "#int(list(str(phix[0]))[2])\n",
    "print(phix,phiy,phiz)\n",
    "cor=[phix,phiy, phiz]\n",
    "cryst_or = np.array(cor)\n",
    "cryst_or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grp = f_out.create_group(\"raw_data_1\")\n",
    "\n",
    "#grp.__setitem__('beamline','NMX')\n",
    "#grp.__setitem__('definition','TOFRAW')\n",
    "#det1 = grp.create_group(\"detector_1\")\n",
    "#dset = det1.create_dataset(\"hist_data\",data=data1)\n",
    "\n",
    "#beamline = grp.create_dataset(\"beamline\", (\"NMX\"))\n",
    "#print(beamline.name)\n",
    "#beamline = \"NMX\"\n",
    "#\"NMX\" = grp['beamline'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filename, 1280**2-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no = filename.split('/')\n",
    "print(no)\n",
    "name_out= no[-1].split('.')[0]\n",
    "print(name_out)\n",
    "file_out = '/Users/justinbergmann/work_flow/test_out/'+name_out+'_out.h5'\n",
    "print(file_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(file_out, 'w') as fo:\n",
    "## create output nexus file\n",
    "   fo.attrs['default'] = 'NMX_data'\n",
    "   nxentry = fo.create_group('NMX_data')\n",
    "   nxentry.attrs[\"NX_class\"] = 'NXentry'\n",
    "   nxentry.attrs['default'] = 'data'\n",
    "   nxentry.attrs['name'] = 'NMX1'\n",
    "   #nxentry.__setitem__('beamline','NMX')\n",
    "   nxentry.__setitem__('name','NMX')\n",
    "   nxentry.__setitem__('definition','TOFRAW')\n",
    "   nxentry.attrs['name'] = \"NMX\"\n",
    "   #nxentry.attrs['name'].__setattr__('name','NMX') \n",
    "\n",
    "#SAMPLE\n",
    "   nx_sample = nxentry.create_group('NXsample')\n",
    "   nx_sample.__setitem__('name','Single_crystal')\n",
    "\n",
    "\n",
    "#Instrument\n",
    "   nx_instrument = nxentry.create_group('NXinstrument')\n",
    "\n",
    "   nx_detector = nxentry.create_group('NXdetector')\n",
    "   det_origen = nx_detector.create_dataset('origen', data=ds_l) \n",
    "   det_origen.attrs['units'] = 'm'\n",
    "\n",
    "   fast_axis = nx_detector.create_dataset('fast_axis', data=fast_l) \n",
    "   slow_axis = nx_detector.create_dataset('slow_axis', data=slow_l) \n",
    "\n",
    "   nx_beam = nxentry.create_group('NXbeam')\n",
    "\n",
    "\n",
    "   \n",
    "   proton = nxentry.create_dataset('proton_charge', data=1)    \n",
    "   \n",
    "   \n",
    "   nx_det1 = nxentry.create_group('detector_1')   \n",
    "   counts = nx_det1.create_dataset('counts', data=[group_t.values], compression=\"gzip\", compression_opts=4)\n",
    "\n",
    "   t_spectrum = nx_det1.create_dataset('t_bin', data=group_t.coords['t'].values, compression=\"gzip\", compression_opts=4)\n",
    "   t_spectrum.attrs['units'] = 'ms'\n",
    "   t_spectrum.attrs['long_name'] = 't_bin TOF (ms)'\n",
    "\n",
    "   pixel_id = nx_det1.create_dataset('pix_id', data=group_t.coords['id'].values, compression=\"gzip\", compression_opts=4)\n",
    "   pixel_id.attrs['units'] = ''\n",
    "   pixel_id.attrs['long_name'] = 'pixel ID'\n",
    "\n",
    "\n",
    "#SOURCE\n",
    "   nx_inst = nxentry.create_group('instrument')\n",
    "   nx_inst.attrs['nr_detector'] = len(d_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   nx_source = nxentry.create_group('NXsource')\n",
    "   nx_source.__setitem__('name','European Spallation Source')\n",
    "   nx_source.__setitem__('short_name','ESS')\n",
    "   nx_source.__setitem__('type','Spallation Neutron Source')\n",
    "   nx_source.__setitem__('distance',-CDist2(source_pos, sample_pos))\n",
    "   nx_source.__setitem__('probe','neutron')\n",
    "   nx_source.__setitem__('target_material','W')\n",
    "\n",
    "   # for i in range(n_det):\n",
    "   #    panel = da3['panel',i].hist(t=t_step)\n",
    "   #    p_name = \"panel_\"+str(i)\n",
    "   #    nxdata = nxentry.create_group(p_name) \n",
    "   #    nxdata.attrs[\"NX_class\"] = 'NXdata'\n",
    "   #    nxdata.attrs['signal'] = 'counts' \n",
    "   #    #ad counds\n",
    "   #    #counts = nxdata.create_dataset('counts', data=panel_0.values)\n",
    "   #    counts = nxdata.create_dataset('counts', data=panel.values)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#    c_or = nxinst.create_dataset('crystal_orientation',data=cryst_or)\n",
    "#    c_or.attrs['unit'] = 'degrees'\n",
    "#    c_or.attrs['long_name'] = 'crystal orientation in Phi (degrees)'\n",
    "    \n",
    "\n",
    "   fo.close()\n",
    "   del fo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(grp['beamline'].items())\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle = h5py.File(file_out)\n",
    "nxs_file =  h5py.File(file_out)\n",
    "print(handle)\n",
    "print(handle['NMX_data'].keys())\n",
    "print(handle['NMX_data/name'][...])\n",
    "\n",
    "print(\"1\",handle['NMX_data'].attrs[\"name\"].encode('utf-8', 'surrogateescape').decode('latin-1'))\n",
    "print(\"2\", handle['NMX_data'].attrs[\"name\"].encode('utf-8', 'surrogateescape'))\n",
    "outp =handle['NMX_data/name'][()].decode('utf-8') #returns numpy array and decoded to string \n",
    "print(type(outp))\n",
    "print(\"out\",outp)\n",
    "\n",
    "\n",
    "print(handle['NMX_data/instrument'].attrs[\"nr_detector\"],type(handle['NMX_data/instrument'].attrs[\"nr_detector\"]))\n",
    "for i in range(nxs_file['NMX_data/instrument'].attrs[\"nr_detector\"]):\n",
    "    print(\"%02d\" % (i + 1) )\n",
    "print(type(nxs_file['NMX_data/instrument'].attrs[\"nr_detector\"]))\n",
    "origen =  nxs_file['NMX_data/NXdetector/origen'][...]\n",
    "print('origen',origen[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#handle['NMX_data'].attrs()\n",
    "#f_out.close()\n",
    "handle.close()\n",
    "del handle\n",
    "outp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((np.pi * 25**2)/16)\n",
    "print(np.pi * 5**2)\n",
    "print(14*7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(file_out, 'r')\n",
    "for key in f.keys():\n",
    "    print(key) #Names of the root level object names in HDF5 file - can be groups or datasets.\n",
    "    print(type(f[key])) # get the object type: usually group or dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "17 * 64**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()  \n",
    "del id_list\n",
    "del x_list\n",
    "del y_list\n",
    "del t_list\n",
    "del id_hist\n",
    "del hist3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current, peak = tracemalloc.get_traced_memory()\n",
    "print('2 current memory [MB]: {}, peak memory [MB]: {} '.format(round((current/(1024*1024)), 2), round((peak /(1024*1024) ), 2) ))\n",
    "# stopping the library\n",
    "tracemalloc.stop()\n",
    "print(\"neded time (h:mm:ss): \", datetime.now() - startTime)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ess",
   "language": "python",
   "name": "ess"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
